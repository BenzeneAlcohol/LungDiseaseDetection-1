{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose\n",
        "This notebook will be used as a tutorial for understanding the steps, formating and other details for the lung disease detection project. You'll notice that this notebook has been split up into multiple sections; this is to make things easier to read, reuse and navigate. You can use the headings of next sections in an actual notebook as is."
      ],
      "metadata": {
        "id": "cwMULBrEkDXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step-3 (Model Building)\n",
        "First we have to study about VGG16 architecture and then implement it from scratch using tensorflow and keras.\n",
        "[Here](https://arxiv.org/pdf/1409.1556v6.pdf) is the link to the original paper.\n",
        "\n",
        "VGG16 is a convolutional neural network architecture which was propsed in the above mentioned paper. It achieved 92.7% accuracy in ImageNet, which has over 14 million images belonging to 1000 classes. \n",
        "\n",
        "You can also refer [this](https://www.youtube.com/watch?v=aJ9wUDBoLUs&t=24s) video for help: \n",
        "\n",
        "**Note**: \n",
        "You can include \n",
        "'***from tensorflow.keras.utils import plot_model***' \n",
        "in your header and '***plot_model(model, show_shapes = True)***' after you have implemented the model. It helps you to visualise the model.\n",
        "You can also refer [this](https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model).\n",
        "\n",
        "Metrics:\n",
        "We can use metrics like accuracy, precision, recall, etc. during the training to evaluate our model.\n",
        "\n",
        "For this we need to include the following line in our code:\n",
        "metrics = ['accuracy', Precision(name = 'precision'), Recall(name = 'recall')]\n",
        "and pass it as a parameter to model.compile().\n",
        "\n",
        "To read more about precision, recall, etc.\n",
        "refer [this](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)\n",
        "\n",
        "\n",
        "Next, we will study about callbacks.\n",
        "\n"
      ],
      "metadata": {
        "id": "dvs5H0H1kKXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step-3 (Callbacks)\n",
        "Tensorflow callbacks are functions or blocks of code which are executed during a specific instant while training a Deep Learning Model.\n",
        "\n",
        "Callbacks are passed to the model via the callbacks argument in fit, which takes a list of callbacks. You can pass any number of callbacks.\n",
        "\n",
        "I will be mentioning only the inbuilt callbacks since right now we are going to be needing only those for now. \n",
        "\n",
        "1. ModelCheckpoint\n",
        "2. EarlyStopping\n",
        "3. ReduceLROnPlatue\n",
        "4. CSVLogger\n",
        "5. TensorBoard\n",
        "\n",
        "All the headings are linked to their documentation, read them for understanding the meaning of each individual parameters. \n",
        "\n",
        "## The [ModelCheckpoint](https://keras.io/api/callbacks/model_checkpoint/) and And [EarlyStopping](https://keras.io/api/callbacks/early_stopping/) Callbacks\n",
        "\n",
        "You can use the EarlyStopping callback to interrupt training once a target metric being monitored has stopped improving for a fixed number of epochs.\n",
        "\n",
        "For instance,this callback allows you to interrupt training as soon as you start overfitting, thus avoiding having to retrain your model for a smaller number of epochs.\n",
        "\n",
        "This callback is typically used in combination with ModelCheckpoint, which lets you continually save the model during training (and, optionally, save only the current best model so far, the version of the model that achieved the best performance at the end of an epoch):\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "import tf.keras\n",
        "\n",
        "# Your List of Callbacks which you will pass to model.fit\n",
        "callbacks_list = [\n",
        "        tf.keras.callbacks.EarlyStopping(  #Interrupts training when improvement stops\n",
        "        monitor='acc',                     #Monitor's the model Validation Accuracy\n",
        "        patience=1,),                      #Interrupts training when accuracy nas stopped improving for more than one epoch.\n",
        "    \n",
        "        tf.keras.callbacks.ModelCheckpoint(#Saves the current weight after every epoch\n",
        "        filepath='my_model.h5',            #Path to destination model file\n",
        "        monitor='val_loss',                #These two arguments mean you wonâ€™t overwrite the model file unless val_loss has improved, \n",
        "        save_best_only=True)               #which allows you to keep the best model seen during training.\n",
        "                 ]                                    \n",
        "model.compile(optimizer='rmsprop',         \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])             \n",
        "model.fit(x, y,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(x_val, y_val))  #Note that because the callback will monitor validation loss and validation accuracy,\n",
        "                                           #you need to pass validation_data to the call to fit.\n",
        "```\n",
        "\n",
        "## [The ReduceOnPlateau Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau)\n",
        "You can use this callback to reduce the learning rate when the validation loss has\n",
        "stopped improving. Reducing or increasing the learning rate in case of a loss plateau is\n",
        "is an effective strategy to get out of local minima during training. The following example\n",
        "uses the ReduceLROnPlateau callback:\n",
        "\n",
        "```\n",
        "callbacks_list = [\n",
        "                 tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                    monitor='val_loss',  #Monitor's the model Validation Accuracy\n",
        "                    factor=0.1,          #Divides the learning rate by 10 when triggered\n",
        "                    patience=10)         #Interrupts training when accuracy nas stopped improving for more than one epoch.\n",
        "                 ]\n",
        "\n",
        "model.fit(x, y,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(x_val, y_val))  #Note that because the callback will monitor validation loss and validation accuracy,\n",
        "                                           #you need to pass validation_data to the call to fit.\n",
        "```\n",
        "\n",
        "## [CSV Logger](https://keras.io/api/callbacks/csv_logger/) (Not too important right now)\n",
        "Callback that streams epoch results to a CSV file.\n",
        "\n",
        "```\n",
        "tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=False)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "model.fit(X_train, Y_train, callbacks=[csv_logger])\n",
        "```\n",
        "\n",
        "## [TensorBoard](https://www.tensorflow.org/tensorboard/get_started)\n",
        "To give a short intro, TensorBoard is a visualization software that comes with any standard TensorFlow installation. TensorBoard helps visualize the model parameters by providing with a suite of web-application that help us to inspect and understand the TensorFlow runs and graphs. Currently, it provides five types of visualizations: scalars, images, audio, histograms, and graphs.\n",
        "\n",
        "```\n",
        "\n",
        "#Load the TensorBoard notebook extension \n",
        "%load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "rm -rf ./logs/\n",
        "\n",
        "#Define Logging Directory & TimeStamp \n",
        "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M\")\n",
        "\n",
        "# TensorBoard CallBack \n",
        "#tensorBoard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#Fitting the Model with TensorBoard CallBack \n",
        "history = model.fit(train_images, train_labels, \n",
        "                    batch_size=batch_size, \n",
        "                    epochs=epochs, \n",
        "                    validation_split = val_size, \n",
        "                    callbacks=[tensorBoard_callback],\n",
        "                    verbose=-1)\n",
        "\n",
        "#Starting TensorBoard\n",
        "%tensorboard logdir logs/fit\n",
        "```\n",
        "There are a a few other built-in callbacks which you can look-up if you want. If you need any help you can contact pranav, harshwardhan or me. Also, If you want to read about custom callbacks you can read [this](https://www.tensorflow.org/guide/keras/custom_callback).\n"
      ],
      "metadata": {
        "id": "-9JIvgmvbl3r"
      }
    }
  ]
}