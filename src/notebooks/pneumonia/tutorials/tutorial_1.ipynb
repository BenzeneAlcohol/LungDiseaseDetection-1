{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose\n",
        "This notebook will be used as a tutorial for understanding the steps, formating and other details for the lung disease detection project. You'll notice that this notebook has been split up into multiple sections; this is to make things easier to read, reuse and navigate. You can use the headings of next sections in an actual notebook as is."
      ],
      "metadata": {
        "id": "lB3oKsApuUpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step-1 (Exploring the dataset)\n",
        "\n",
        "##1. Viewing examples from each class\n",
        "\n",
        " Firstly we will be using the OS module of python to iterate through the images. Followng functions will be useful:\n",
        " i. os.listdir(dir): this function gives us the list of all the files and directories in the specified directory.\n",
        " ii. os.path.join(path,*paths): this function is used to concatenate various paths using the '/' separator.\n",
        "Using this we can obtain the image pateh.\n",
        "\n",
        " Once we have the path for the image, we wll use some open cv functions to deal with the images:\n",
        " i. first, we read the image using the image path.\n",
        " ii. then we convert the color format from BGR to RGB.\n",
        " iii. next, we resize the image.\n",
        "\n",
        " Finally, when we have enough number of images to display we display the images from each class using matplotlib.\n",
        "\n",
        "\n",
        "##2. Understand distribution of images across various classes\n",
        "\n",
        "Here again using the OS module we iterate through the directory which has folders for each class in it.\n",
        "We find the number of images in each class. \n",
        "\n",
        "Finally we plot the number of images in each class in the form of a bar graph.\n",
        "We do this this for train, test and val images.\n",
        "\n",
        "Once we have the bar graphs we can see the distribution of images across classes.\n",
        "\n",
        "\n",
        "##3. Find appropriate class weights\n",
        "\n",
        "We can see that the dataset is imbalanced as we have more pneumonia images and lesser normal images. One way of dealing with class imabalnce is to use class weights ( others include oversampling and undersampling, two-stage training, etc.).\n",
        "\n",
        "Since we are dealing with binary classification here, the class weights can simply be obtained by calculating the number of images in each class and inverting it. This way we ensure that the prediction error is larger when an image of the less frequent class is wrongly identified.\n",
        "\n",
        "We have already calculated the number of images in each class in (2), so we simply use the formula:\n",
        "\n",
        "### class_wt = total / (freq_of_class*number_of_classes).\n",
        "here number_of_classes=2.\n",
        "\n",
        "Finally, we have the class weights for each class.  "
      ],
      "metadata": {
        "id": "9O_wbhZa5jNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Data Generators (Step - 2)\n",
        "Image Augmentation is the process of expanding the image training data, by using transformations such as random rotations, shear transforms, shifts zooms and flips, on available image data. The ImageDataGenerator class of Keras allows us to achieve the same. The ImageDataGenerator generates batches of tensor image-data with real-time augmentation. The data will be looped over in batches.\n",
        "The pattern for using the ImageDataGenerator class is used as follows:\n",
        "\n",
        "\n",
        "1.   Construct and configure an instance of the ImageDataGenerator class.\n",
        "2.   Retrieve an iterator by calling the flow_from_directory() function.\n",
        "3.   Use the iterator in the training or evaluation of a model.\n",
        "\n",
        "We use the flow_from_directory method, which is a generator, which takes in the path to the parent directory containing different classes of image data and generates batches of images to be fed to the ImageDataGenerator. This is the expected directory structure of the flow_from_directory method.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Parent_directory\n",
        "      |--Class_1_folder\n",
        "      |\n",
        "      |--Class_2_folder\n",
        "      |\n",
        "      |--Class_3_folder\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Save the images of each class in separate folders and pass the path of the parent directory to the flow_from_directory method. In the ImageDataGenerator class, we will specify only the transformations we wish to apply to your images.\n",
        "\n",
        "This is how you instantiate the Image Data Generator\n",
        "If you wish to see all the parameters check [this](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator). You can have different data generators for test, train etc.\n",
        "\n",
        "```\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#instantiate the ImageDataGenerator class\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        height_shift_range=0.2,\n",
        "        width_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "```\n",
        "\n",
        "Next, an iterator is required to progressively load images for a single dataset.\n",
        "This requires calling the flow_from_directory() function and specifying the dataset directory, such as the train, test, or validation directory.\n",
        "\n",
        "The function also allows you to configure more details related to the loading of images. Of note is the ‘target_size‘ argument that allows you to load all images to a specific size, which is often required when modelling. The function defaults to square images with the size (256, 256).\n",
        "\n",
        "The function also allows you to specify the type of classification task via the ‘class_mode‘ argument, specifically whether it is ‘binary‘ or a multi-class classification ‘categorical‘. We'll be using 'binary' as we have only 2 classes.\n",
        "\n",
        "The default ‘batch_size‘ is 32, which means that 32 randomly selected images from across the classes in the dataset will be returned in each batch when training. Larger or smaller batches may be desired. \n",
        "\n",
        "You may also want to return batches in a deterministic order when evaluating a model, which you can do by setting ‘shuffle‘ to ‘False.’\n",
        "\n",
        "We can use the same ImageDataGenerator to prepare separate iterators for separate dataset directories. This is useful if we would like the same pixel scaling applied to multiple datasets (e.g. trian, test, etc.).\n",
        "\n",
        "```\n",
        "# load and iterate training dataset\n",
        "train_it = datagen.flow_from_directory('data/train/', class_mode='binary', batch_size=64)\n",
        "# load and iterate validation dataset\n",
        "val_it = datagen.flow_from_directory('data/validation/', class_mode='binary', batch_size=64)\n",
        "# load and iterate test dataset\n",
        "test_it = datagen.flow_from_directory('data/test/', class_mode='binary', batch_size=64)\n",
        "\n",
        "```\n",
        "You can also see the examples given [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) by scrolling down below\n",
        "Also you can have a look at [this](https://www.youtube.com/watch?v=uqomO_BZ44g) if you like to learn using videos. You need to cover only till the datagenerator part. \n",
        "\n",
        "So now you are done with creating the generators. Now you'll have to create the model and fit it. But that's for the next tutorial. \n"
      ],
      "metadata": {
        "id": "tCx7Dwm0uWoo"
      }
    }
  ]
}